{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doctor AI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9DZ-tqwddkI0",
        "4-b7whNrzGcP",
        "CaVUPpkxDs1h"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Doctor AI: Predicting Clinical Events via Recurrent Neural Networks**\n",
        "\n",
        "Edward Choi, Mohammad Taha Bahadori, Andy Schuetz, Walter F. Stewart, Jimeng Sun\n",
        "\n",
        "[Machine Learning for Healthcare 2016](http://proceedings.mlr.press/v56/Choi16)\n",
        "\n",
        "Model Parameters in Original Paper:\n",
        "1.   Number of Epochs: 20\n",
        "2.   L2 Regularization Coefficient: 0.001\n",
        "3.   GRU Hidden Layer Dimension: 2000\n",
        "\n",
        "\n",
        "\n",
        "PyTorch Implementation by [Leisheng Yu](https://github.com/ThunderbornSakana) (leisheng.yu@alumni.emory.edu)\n",
        "\n",
        "\n",
        "# **Diagnosis Prediction -- Multi-label Binary Prediction Task**"
      ],
      "metadata": {
        "id": "_HmodOJ4bd5v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Package Setup**"
      ],
      "metadata": {
        "id": "9DZ-tqwddkI0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1o2jJZ3naUVZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle as pickle\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import scipy.sparse as sps\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "from collections import OrderedDict\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Data**"
      ],
      "metadata": {
        "id": "4-b7whNrzGcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Format Combo for Doctor AI\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_train_codes_x.pkl', 'rb') as f0:\n",
        "  binary_train_codes_x = pickle.load(f0)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_test_codes_x.pkl', 'rb') as f1:\n",
        "  binary_test_codes_x = pickle.load(f1)\n",
        "\n",
        "train_codes_y = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_codes_y.npy')\n",
        "train_visit_lens = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_visit_lens.npy')\n",
        "test_codes_y = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_codes_y.npy')\n",
        "test_visit_lens = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_visit_lens.npy')"
      ],
      "metadata": {
        "id": "NSZx0z_72Nav"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_and_pad_input(x):\n",
        "  tempX = []\n",
        "  for ele in x:\n",
        "    tempX.append(torch.tensor(ele).to(torch.float32))\n",
        "  x_padded = pad_sequence(tempX, batch_first=True, padding_value=0)\n",
        "  return x_padded"
      ],
      "metadata": {
        "id": "m_H30hvwDDPU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_X_train = transform_and_pad_input(binary_train_codes_x)\n",
        "padded_X_test = transform_and_pad_input(binary_test_codes_x)\n",
        "trans_y_train = torch.tensor(train_codes_y)\n",
        "trans_y_test = torch.tensor(test_codes_y)"
      ],
      "metadata": {
        "id": "-SpOQ3TYDFcf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyData(data.Dataset):\n",
        "    def __init__(self, data_seq, data_label, data_len):\n",
        "        self.data_seq = data_seq\n",
        "        self.data_label = data_label\n",
        "        self.data_len = data_len\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.data_seq)\n",
        " \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_seq[idx], self.data_label[idx], self.data_len[idx]\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "mTeNrCk1DHoN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Starts**"
      ],
      "metadata": {
        "id": "0cPrB9MbDTEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Doctor_AI(nn.Module):\n",
        "  def __init__(self, input_dim, input_dim2, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "    super(Doctor_AI, self).__init__()\n",
        "    self.layer_dim = layer_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    # Embedding layer to project input to lower dimensional space\n",
        "    self.emb_layer = nn.Linear(input_dim, input_dim2, bias=True)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    # GRU layers for processing sequences\n",
        "    self.gru = nn.GRU(\n",
        "        input_dim2, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "    )\n",
        "    # Fully connected layer for classification\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout_layer = nn.Dropout(p=dropout_prob)\n",
        "    self.softmax = torch.nn.Softmax()\n",
        "        \n",
        "  def forward(self, x, x_len):\n",
        "    # Initializing hidden state for first input with zeros\n",
        "    weight0 = next(self.parameters()).data\n",
        "    h0 = weight0.new(self.layer_dim, x.size(0), self.hidden_dim).zero_().to(device)\n",
        "    h0 = h0.data\n",
        "    # Project input to lower dimensional space\n",
        "    x = self.tanh(self.emb_layer(x))\n",
        "    x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "    # Forward propagation by passing in the input and hidden state into the model\n",
        "    out, _ = self.gru(x_packed, h0)\n",
        "    out, out_lengths = pad_packed_sequence(out, batch_first=True)\n",
        "    # Reshaping the outputs in the shape of (batch_size, hidden_size)\n",
        "    # so that it can fit into the fully connected layer\n",
        "    out = out[list(torch.arange(len(out)).cpu()), list((out_lengths-1).cpu()), :]\n",
        "    # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "    out = self.softmax(self.fc(self.dropout_layer(out)))\n",
        "    return out"
      ],
      "metadata": {
        "id": "YWPIeB6RDVzr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Loop**"
      ],
      "metadata": {
        "id": "CaVUPpkxDs1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doctor_AI(torch.Tensor.size(padded_X_train[0])[1], 2000, 2000, 1, torch.Tensor.size(padded_X_train[0])[1], 0.5)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "zYkoQYoaDwDw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is for diagnosis prediction\n",
        "def evaluate_model(pred, label, k1, k2, k3, k4, k5, k6):\n",
        "  pred2_k1 = torch.zeros_like(pred[0])\n",
        "  pred3_k1 = []\n",
        "  pred2_k2 = torch.zeros_like(pred[0])\n",
        "  pred3_k2 = []\n",
        "  pred2_k3 = torch.zeros_like(pred[0])\n",
        "  pred3_k3 = []\n",
        "  pred2_k4 = torch.zeros_like(pred[0])\n",
        "  pred3_k4 = []\n",
        "  pred2_k5 = torch.zeros_like(pred[0])\n",
        "  pred3_k5 = []\n",
        "  pred2_k6 = torch.zeros_like(pred[0])\n",
        "  pred3_k6 = []\n",
        "  # above is for recall and precision\n",
        "  true3 = [] # this is for label\n",
        "  pred4 = [] # this is for ndcg\n",
        "  for i in range(len(pred)):\n",
        "    pred2_k1[torch.topk(pred[i], k1).indices] = 1\n",
        "    pred3_k1.append(pred2_k1.cpu().detach().tolist())\n",
        "    pred2_k2[torch.topk(pred[i], k2).indices] = 1\n",
        "    pred3_k2.append(pred2_k2.cpu().detach().tolist())\n",
        "    pred2_k3[torch.topk(pred[i], k3).indices] = 1\n",
        "    pred3_k3.append(pred2_k3.cpu().detach().tolist())\n",
        "    pred2_k4[torch.topk(pred[i], k4).indices] = 1\n",
        "    pred3_k4.append(pred2_k4.cpu().detach().tolist())\n",
        "    pred2_k5[torch.topk(pred[i], k5).indices] = 1\n",
        "    pred3_k5.append(pred2_k5.cpu().detach().tolist())\n",
        "    pred2_k6[torch.topk(pred[i], k6).indices] = 1\n",
        "    pred3_k6.append(pred2_k6.cpu().detach().tolist())\n",
        "    pred4.append(pred[i].cpu().detach().tolist())\n",
        "    true3.append(label[i].cpu().detach().tolist())\n",
        "  \n",
        "  metric_p_1 = precision_score(true3, pred3_k1, average='samples')\n",
        "  metric_p_2 = precision_score(true3, pred3_k2, average='samples')\n",
        "  metric_p_3 = precision_score(true3, pred3_k3, average='samples')\n",
        "  metric_p_4 = precision_score(true3, pred3_k4, average='samples')\n",
        "  metric_p_5 = precision_score(true3, pred3_k5, average='samples')\n",
        "  metric_p_6 = precision_score(true3, pred3_k6, average='samples')\n",
        "  \n",
        "  metric_r_1 = recall_score(true3, pred3_k1, average='samples')\n",
        "  metric_r_2 = recall_score(true3, pred3_k2, average='samples')\n",
        "  metric_r_3 = recall_score(true3, pred3_k3, average='samples')\n",
        "  metric_r_4 = recall_score(true3, pred3_k4, average='samples')\n",
        "  metric_r_5 = recall_score(true3, pred3_k5, average='samples')\n",
        "  metric_r_6 = recall_score(true3, pred3_k6, average='samples')\n",
        "  \n",
        "  metric_n_1 = ndcg_score(true3, pred4, k=k1)\n",
        "  metric_n_2 = ndcg_score(true3, pred4, k=k2)\n",
        "  metric_n_3 = ndcg_score(true3, pred4, k=k3)\n",
        "  metric_n_4 = ndcg_score(true3, pred4, k=k4)\n",
        "  metric_n_5 = ndcg_score(true3, pred4, k=k5)\n",
        "  metric_n_6 = ndcg_score(true3, pred4, k=k6)\n",
        "  return metric_p_1, metric_r_1, metric_n_1, metric_p_2, metric_r_2, metric_n_2, metric_p_3, metric_r_3, metric_n_3, metric_p_4, metric_r_4, metric_n_4, metric_p_5, metric_r_5, metric_n_5, metric_p_6, metric_r_6, metric_n_6"
      ],
      "metadata": {
        "id": "b2BthMo_UFyW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize evaluation record lists\n",
        "metric_p1_list = []\n",
        "metric_p2_list = []\n",
        "metric_p3_list = []\n",
        "metric_p4_list = []\n",
        "metric_p5_list = []\n",
        "metric_p6_list = []\n",
        "metric_r1_list = []\n",
        "metric_r2_list = []\n",
        "metric_r3_list = []\n",
        "metric_r4_list = []\n",
        "metric_r5_list = []\n",
        "metric_r6_list = []\n",
        "metric_n1_list = []\n",
        "metric_n2_list = []\n",
        "metric_n3_list = []\n",
        "metric_n4_list = []\n",
        "metric_n5_list = []\n",
        "metric_n6_list = []"
      ],
      "metadata": {
        "id": "3zgSWLSdENWg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mode\n",
        "model.train()\n",
        "# Loss and optimizer (learning rate)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
        "# Initialize data loader for training\n",
        "training_data = MyData(padded_X_train, trans_y_train, train_visit_lens)\n",
        "train_loader = DataLoader(training_data, batch_size=100, shuffle=True)\n",
        "total_step = len(train_loader)\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (patients, labels, seq_lengths) in enumerate(train_loader):\n",
        "    patients = patients.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Forward pass\n",
        "    outputs = model(patients, seq_lengths)\n",
        "    loss = criterion(outputs, labels.to(torch.float32))\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Tracking\n",
        "    if (i+1) % 25 == 0:\n",
        "      print('Epoch: [{}/{}], Step: [{}/{}], Loss: {}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "  if (epoch+1) % 1 == 0:\n",
        "    model.eval()\n",
        "    # Initialize data loader for testing\n",
        "    test_data = MyData(padded_X_test, trans_y_test, test_visit_lens)\n",
        "    test_loader = DataLoader(test_data, batch_size=len(padded_X_test), shuffle=True)\n",
        "    # Testing\n",
        "    for (patients, labels, seq_lengths) in test_loader:\n",
        "        patients = patients.to(device)\n",
        "        labels = labels.to(device)\n",
        "        pred = model(patients, seq_lengths)\n",
        "        # Subject to Change! @k for evaluation\n",
        "        metric_p1, metric_r1, metric_n1, metric_p2, metric_r2, metric_n2, metric_p3, metric_r3, metric_n3, metric_p4, metric_r4, metric_n4, metric_p5, metric_r5, metric_n5, metric_p6, metric_r6, metric_n6, = evaluate_model(pred, labels, 5, 10, 15, 20, 25, 30)\n",
        "        ###############################\n",
        "        metric_p1_list.append(metric_p1)\n",
        "        metric_p2_list.append(metric_p2)\n",
        "        metric_p3_list.append(metric_p3)\n",
        "        metric_p4_list.append(metric_p4)\n",
        "        metric_p5_list.append(metric_p5)\n",
        "        metric_p6_list.append(metric_p6)\n",
        "        ###############################\n",
        "        metric_r1_list.append(metric_r1)\n",
        "        metric_r2_list.append(metric_r2)\n",
        "        metric_r3_list.append(metric_r3)\n",
        "        metric_r4_list.append(metric_r4)\n",
        "        metric_r5_list.append(metric_r5)\n",
        "        metric_r6_list.append(metric_r6)\n",
        "        ###############################\n",
        "        metric_n1_list.append(metric_n1)\n",
        "        metric_n2_list.append(metric_n2)\n",
        "        metric_n3_list.append(metric_n3)\n",
        "        metric_n4_list.append(metric_n4)\n",
        "        metric_n5_list.append(metric_n5)\n",
        "        metric_n6_list.append(metric_n6)\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "R8eSmkaAEPq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mortality Prediction -- Binary Prediction Task**"
      ],
      "metadata": {
        "id": "2swPlEE_BcJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Package Setup**"
      ],
      "metadata": {
        "id": "fqDNWvcRBoK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pickle as pickle\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import scipy.sparse as sps\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence\n",
        "from collections import OrderedDict\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import ndcg_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "JaOnJ-dVBmUq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Load Data**"
      ],
      "metadata": {
        "id": "KtDVg7YTBvEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Binary Format Combo for Doctor AI\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_train_codes_x.pkl', 'rb') as f0:\n",
        "  binary_train_codes_x = pickle.load(f0)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_test_codes_x.pkl', 'rb') as f1:\n",
        "  binary_test_codes_x = pickle.load(f1)\n",
        "\n",
        "train_visit_lens = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_visit_lens.npy')\n",
        "train_mort = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_mort.npy')\n",
        "test_visit_lens = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_visit_lens.npy')\n",
        "test_mort = np.load('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_mort.npy')"
      ],
      "metadata": {
        "id": "U9pOExj8BuOb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_and_pad_input(x):\n",
        "  tempX = []\n",
        "  for ele in x:\n",
        "    tempX.append(torch.tensor(ele).to(torch.float32))\n",
        "  x_padded = pad_sequence(tempX, batch_first=True, padding_value=0)\n",
        "  return x_padded"
      ],
      "metadata": {
        "id": "W5QncDLNB6Gs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "padded_X_train = transform_and_pad_input(binary_train_codes_x)\n",
        "padded_X_test = transform_and_pad_input(binary_test_codes_x)\n",
        "trans_y_train = torch.tensor(train_mort)\n",
        "trans_y_test = torch.tensor(test_mort)"
      ],
      "metadata": {
        "id": "2ZKfL0TiB84S"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyData(data.Dataset):\n",
        "    def __init__(self, data_seq, data_label, data_len):\n",
        "        self.data_seq = data_seq\n",
        "        self.data_label = data_label\n",
        "        self.data_len = data_len\n",
        " \n",
        "    def __len__(self):\n",
        "        return len(self.data_seq)\n",
        " \n",
        "    def __getitem__(self, idx):\n",
        "        return self.data_seq[idx], self.data_label[idx], self.data_len[idx]\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "PXDvtMWxB_Gl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Starts**"
      ],
      "metadata": {
        "id": "JJdr-IwVCNeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Doctor_AI(nn.Module):\n",
        "  def __init__(self, input_dim, input_dim2, hidden_dim, layer_dim, output_dim, dropout_prob):\n",
        "    super(Doctor_AI, self).__init__()\n",
        "    self.layer_dim = layer_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    # Embedding layer to project input to lower dimensional space\n",
        "    self.emb_layer = nn.Linear(input_dim, input_dim2, bias=True)\n",
        "    self.tanh = torch.nn.Tanh()\n",
        "    # GRU layers for processing sequences\n",
        "    self.gru = nn.GRU(\n",
        "        input_dim2, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "    )\n",
        "    # Fully connected layer for classification\n",
        "    self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout_layer = nn.Dropout(p=dropout_prob)\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "        \n",
        "  def forward(self, x, x_len):\n",
        "    # Initializing hidden state for first input with zeros\n",
        "    weight0 = next(self.parameters()).data\n",
        "    h0 = weight0.new(self.layer_dim, x.size(0), self.hidden_dim).zero_().to(device)\n",
        "    h0 = h0.data\n",
        "    # Project input to lower dimensional space\n",
        "    x = self.tanh(self.emb_layer(x))\n",
        "    x_packed = pack_padded_sequence(x, x_len, batch_first=True, enforce_sorted=False)\n",
        "    # Forward propagation by passing in the input and hidden state into the model\n",
        "    out, _ = self.gru(x_packed, h0)\n",
        "    out, out_lengths = pad_packed_sequence(out, batch_first=True)\n",
        "    # Reshaping the outputs in the shape of (batch_size, hidden_size)\n",
        "    # so that it can fit into the fully connected layer\n",
        "    out = out[list(torch.arange(len(out)).cpu()), list((out_lengths-1).cpu()), :]\n",
        "    # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "    out = self.sigmoid(self.fc(self.dropout_layer(out)))\n",
        "    return out"
      ],
      "metadata": {
        "id": "JgUffuFNCUCu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Loop**"
      ],
      "metadata": {
        "id": "E5v53w8ICbDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Doctor_AI(torch.Tensor.size(padded_X_train[0])[1], 2000, 2000, 1, 1, 0.5)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "9CrxCvxECd1L"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize evaluation record lists\n",
        "auc_list = []\n",
        "acc_list = []"
      ],
      "metadata": {
        "id": "PEjhligNCi6v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training mode\n",
        "model.train()\n",
        "# Loss and optimizer (learning rate)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=0.001)\n",
        "# Initialize data loader for training\n",
        "training_data = MyData(padded_X_train, trans_y_train, train_visit_lens)\n",
        "train_loader = DataLoader(training_data, batch_size=1000, shuffle=True)\n",
        "total_step = len(train_loader)\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (patients, labels, seq_lengths) in enumerate(train_loader):\n",
        "    patients = patients.to(device)\n",
        "    labels = labels.to(device)\n",
        "    # Forward pass\n",
        "    outputs = model(patients, seq_lengths)\n",
        "    outputs = torch.reshape(outputs, (len(outputs),))\n",
        "    loss = criterion(outputs, labels.to(torch.float32))\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # Tracking\n",
        "    if (i+1) % 1 == 0:\n",
        "      print('Epoch: [{}/{}], Step: [{}/{}], Loss: {}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "  if (epoch+1) % 1 == 0:\n",
        "    model.eval()\n",
        "    # Initialize data loader for testing\n",
        "    test_data = MyData(padded_X_test, trans_y_test, test_visit_lens)\n",
        "    test_loader = DataLoader(test_data, batch_size=len(padded_X_test), shuffle=True)\n",
        "    # Testing\n",
        "    for (patients, labels, seq_lengths) in test_loader:\n",
        "        patients = patients.to(device)\n",
        "        labels = labels.to(device)\n",
        "        pred = model(patients, seq_lengths)\n",
        "        pred = torch.reshape(pred, (len(pred),))\n",
        "        pred_auc = pred.detach().cpu().numpy()\n",
        "        pred_acc = np.round(pred_auc)\n",
        "        auc_list.append(roc_auc_score(labels.detach().cpu().numpy(), pred_auc))\n",
        "        acc_list.append(accuracy_score(labels.detach().cpu().numpy(), pred_acc))\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "LNCvPvXFCkg8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
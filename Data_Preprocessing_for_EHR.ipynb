{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Preprocessing_for_EHR.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7NaiTXpPUe-J",
        "f0xujg9mEszQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing for Longitudinal EHR Data**\n",
        "\n",
        "This notebook preprocesses [MIMIC-III](https://physionet.org/content/mimiciii/1.4/) data for two tasks: diagnosis prediction (multi-label binary) and mortality prediction (binary). Also, this notebook can generate and prepare [ICD-9](https://www.cdc.gov/nchs/icd/icd9cm.htm) hierarchy of existing diagnosis codes in MIMIC-III as well as patient-code adjacency matrix, code-code adjacency matrix, and code map which is a dictionary of diagnosis codes.\n",
        "\n",
        "This notebook prepares input into two formats: one is binary vector, the other one is set vector."
      ],
      "metadata": {
        "id": "Vxon2gI7VOeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Package Setup**"
      ],
      "metadata": {
        "id": "7NaiTXpPUe-J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phe5qcodUR2W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle as pickle\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import scipy.sparse as sps\n",
        "import torch\n",
        "from copy import deepcopy\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torch.nn import functional as F\n",
        "from collections import OrderedDict\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing Version 2**"
      ],
      "metadata": {
        "id": "f0xujg9mEszQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_admission(path) -> dict:\n",
        "    print('parsing ADMISSIONS.csv ...')\n",
        "    admission_path = os.path.join(path, 'ADMISSIONS.csv')\n",
        "    admissions = pd.read_csv(\n",
        "        admission_path,\n",
        "        usecols=['SUBJECT_ID', 'HADM_ID', 'ADMITTIME'],\n",
        "        converters={ 'SUBJECT_ID': np.int, 'HADM_ID': np.int, 'ADMITTIME': np.str }\n",
        "    )\n",
        "    all_patients = dict()\n",
        "    for i, row in admissions.iterrows():\n",
        "        pid = row['SUBJECT_ID']\n",
        "        admission_id = row['HADM_ID']\n",
        "        admission_time = datetime.strptime(row['ADMITTIME'], '%Y-%m-%d %H:%M:%S')\n",
        "        if pid not in all_patients:\n",
        "            all_patients[pid] = []\n",
        "        admission = all_patients[pid]\n",
        "        admission.append({\n",
        "            'admission_id': admission_id,\n",
        "            'admission_time': admission_time\n",
        "        })\n",
        "\n",
        "    patient_admission = dict()\n",
        "    for pid, admissions in all_patients.items():\n",
        "        if len(admissions) > 1:\n",
        "            patient_admission[pid] = sorted(admissions, key=lambda admission: admission['admission_time'])\n",
        "\n",
        "    return patient_admission"
      ],
      "metadata": {
        "id": "wyLV5pBJEvqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_diagnoses(path, patient_admission: dict) -> dict:\n",
        "    print('parsing DIAGNOSES_ICD.csv ...')\n",
        "    diagnoses_path = os.path.join(path, 'DIAGNOSES_ICD.csv')\n",
        "    diagnoses = pd.read_csv(\n",
        "        diagnoses_path,\n",
        "        usecols=['SUBJECT_ID', 'HADM_ID', 'ICD9_CODE'],\n",
        "        converters={ 'SUBJECT_ID': np.int, 'HADM_ID': np.int, 'ICD9_CODE': np.str }\n",
        "    )\n",
        "\n",
        "    def to_standard_icd9(code: str):\n",
        "        split_pos = 4 if code.startswith('E') else 3\n",
        "        icd9_code = code[:split_pos] + '.' + code[split_pos:] if len(code) > split_pos else code\n",
        "        return icd9_code\n",
        "\n",
        "    admission_codes = dict()\n",
        "    for i, row in diagnoses.iterrows():\n",
        "        pid = row['SUBJECT_ID']\n",
        "        if pid in patient_admission:\n",
        "            admission_id = row['HADM_ID']\n",
        "            code = row['ICD9_CODE']\n",
        "            if code == '':\n",
        "                continue\n",
        "            code = to_standard_icd9(code)\n",
        "            if admission_id not in admission_codes:\n",
        "                codes = []\n",
        "                admission_codes[admission_id] = codes\n",
        "            else:\n",
        "                codes = admission_codes[admission_id]\n",
        "            codes.append(code)\n",
        "\n",
        "    return admission_codes"
      ],
      "metadata": {
        "id": "Uj8JAMA5E197"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calibrate_patient_by_admission(patient_admission: dict, admission_codes: dict):\n",
        "    print('calibrating patients by admission ...')\n",
        "    del_pids = []\n",
        "    for pid, admissions in patient_admission.items():\n",
        "        for admission in admissions:\n",
        "            if admission['admission_id'] not in admission_codes:\n",
        "                break\n",
        "        else:\n",
        "            continue\n",
        "        del_pids.append(pid)\n",
        "    for pid in del_pids:\n",
        "        admissions = patient_admission[pid]\n",
        "        for admission in admissions:\n",
        "            if admission['admission_id'] in admission_codes:\n",
        "                del admission_codes[admission['admission_id']]\n",
        "        del patient_admission[pid]"
      ],
      "metadata": {
        "id": "vJRLhVFXE5gK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_path = '/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/'\n",
        "patient_admission = parse_admission(raw_path)\n",
        "admission_codes = parse_diagnoses(raw_path, patient_admission)\n",
        "calibrate_patient_by_admission(patient_admission, admission_codes)\n",
        "print('There are %d valid patients' % len(patient_admission))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9VKY7_BFePh",
        "outputId": "8021c355-1a7d-4659-8a5f-94013b1a8aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "parsing ADMISSIONS.csv ...\n",
            "parsing DIAGNOSES_ICD.csv ...\n",
            "calibrating patients by admission ...\n",
            "There are 7493 valid patients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_admission_num = 0\n",
        "for pid, admissions in patient_admission.items():\n",
        "    if len(admissions) > max_admission_num:\n",
        "        max_admission_num = len(admissions)\n",
        "max_code_num_in_a_visit = 0\n",
        "for admission_id, codes in admission_codes.items():\n",
        "    if len(codes) > max_code_num_in_a_visit:\n",
        "        max_code_num_in_a_visit = len(codes)"
      ],
      "metadata": {
        "id": "0TerN1BNFiQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_code(admission_codes: dict) -> (dict, dict):\n",
        "    print('encoding code ...')\n",
        "    code_map = dict()\n",
        "    for i, (admission_id, codes) in enumerate(admission_codes.items()):\n",
        "        for code in codes:\n",
        "            if code not in code_map:\n",
        "                code_map[code] = len(code_map) + 1\n",
        "\n",
        "    admission_codes_encoded = {\n",
        "        admission_id: [code_map[code] for code in codes]\n",
        "        for admission_id, codes in admission_codes.items()\n",
        "    }\n",
        "    return admission_codes_encoded, code_map"
      ],
      "metadata": {
        "id": "BtYSCC0hFnd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_time_duration(patient_admission: dict) -> dict:\n",
        "    print('encoding time duration ...')\n",
        "    patient_time_duration_encoded = dict()\n",
        "    for pid, admissions in patient_admission.items():\n",
        "        duration = [0]\n",
        "        for i in range(1, len(admissions)):\n",
        "            days = (admissions[i]['admission_time'] - admissions[i - 1]['admission_time']).days\n",
        "            duration.append(days)\n",
        "        patient_time_duration_encoded[pid] = duration\n",
        "    return patient_time_duration_encoded"
      ],
      "metadata": {
        "id": "_chYjEt-Fs8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_patients(patient_admission: dict, admission_codes: dict, code_map: dict, seed=6669) -> (np.ndarray, np.ndarray):\n",
        "    print('splitting train, valid, and test pids')\n",
        "    np.random.seed(seed)\n",
        "    common_pids = set()\n",
        "    for i, code in enumerate(code_map):\n",
        "        print('\\r\\t%.2f%%' % ((i + 1) * 100 / len(code_map)), end='')\n",
        "        for pid, admissions in patient_admission.items():\n",
        "            for admission in admissions:\n",
        "                codes = admission_codes[admission['admission_id']]\n",
        "                if code in codes:\n",
        "                    common_pids.add(pid)\n",
        "                    break\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "    print('\\r\\t100%')\n",
        "    max_admission_num = 0\n",
        "    pid_max_admission_num = 0\n",
        "    for pid, admissions in patient_admission.items():\n",
        "        if len(admissions) > max_admission_num:\n",
        "            max_admission_num = len(admissions)\n",
        "            pid_max_admission_num = pid\n",
        "    common_pids.add(pid_max_admission_num)\n",
        "    remaining_pids = np.array(list(set(patient_admission.keys()).difference(common_pids)))\n",
        "    np.random.shuffle(remaining_pids)\n",
        "\n",
        "    train_num = 7000\n",
        "    valid_num = 0\n",
        "    train_pids = np.array(list(common_pids.union(set(remaining_pids[:(train_num - len(common_pids))].tolist()))))\n",
        "    # valid_pids = remaining_pids[(train_num - len(common_pids)):(train_num + valid_num - len(common_pids))]\n",
        "    test_pids = remaining_pids[(train_num + valid_num - len(common_pids)):]\n",
        "    return train_pids, test_pids"
      ],
      "metadata": {
        "id": "CItbo8wHFxsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "admission_codes_encoded, code_map = encode_code(admission_codes)\n",
        "patient_time_duration_encoded = encode_time_duration(patient_admission)\n",
        "\n",
        "code_num = len(code_map)\n",
        "\n",
        "train_pids, test_pids = split_patients(\n",
        "    patient_admission=patient_admission,\n",
        "    admission_codes=admission_codes,\n",
        "    code_map=code_map\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-JxGKKvF2fI",
        "outputId": "6db82fb4-dc38-4299-a379-0df778912668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoding code ...\n",
            "encoding time duration ...\n",
            "splitting train, valid, and test pids\n",
            "\t100%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_code_xy(pids: np.ndarray,\n",
        "                  patient_admission: dict,\n",
        "                  admission_codes_encoded: dict,\n",
        "                  max_admission_num: int,\n",
        "                  code_num: int,\n",
        "                  max_code_num_in_a_visit: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    print('building train/valid/test codes features and labels ...')\n",
        "    n = len(pids)\n",
        "    x = np.zeros((n, max_admission_num, max_code_num_in_a_visit), dtype=int)\n",
        "    y = np.zeros((n, code_num), dtype=int)\n",
        "    lens = np.zeros((n, ), dtype=int)\n",
        "    for i, pid in enumerate(pids):\n",
        "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
        "        admissions = patient_admission[pid]\n",
        "        for k, admission in enumerate(admissions[:-1]):\n",
        "            codes = admission_codes_encoded[admission['admission_id']]\n",
        "            x[i][k][:len(codes)] = codes\n",
        "        codes = np.array(admission_codes_encoded[admissions[-1]['admission_id']]) - 1\n",
        "        y[i][codes] = 1\n",
        "        lens[i] = len(admissions) - 1\n",
        "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
        "    return x, y, lens"
      ],
      "metadata": {
        "id": "AC7Gib9dF5BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_time_duration_xy(pids: np.ndarray,\n",
        "                           patient_time_duration_encoded: dict,\n",
        "                           max_admission_num: int) -> (np.ndarray, np.ndarray):\n",
        "    print('building train/valid/test time duration features and labels ...')\n",
        "    n = len(pids)\n",
        "    x = np.zeros((n, max_admission_num))\n",
        "    y = np.zeros((n, ))\n",
        "    for i, pid in enumerate(pids):\n",
        "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
        "        duration = patient_time_duration_encoded[pid]\n",
        "        x[i][:len(duration) - 1] = duration[:-1]\n",
        "        y[i] = duration[-1]\n",
        "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "Fj5ObdvWGsoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_codes_x, train_codes_y, train_visit_lens = build_code_xy(train_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)\n",
        "test_codes_x, test_codes_y, test_visit_lens = build_code_xy(test_pids, patient_admission, admission_codes_encoded, max_admission_num, code_num, max_code_num_in_a_visit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj5X564jGuvG",
        "outputId": "04b43126-3e1c-411a-bd27-ed2c6e20f3f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building train/valid/test codes features and labels ...\n",
            "\t7000 / 7000\n",
            "building train/valid/test codes features and labels ...\n",
            "\t493 / 493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_icd9_range(range_: str) -> (str, str, int, int):\n",
        "    ranges = range_.lstrip().split('-')\n",
        "    if ranges[0][0] == 'V':\n",
        "        prefix = 'V'\n",
        "        format_ = '%02d'\n",
        "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
        "    elif ranges[0][0] == 'E':\n",
        "        prefix = 'E'\n",
        "        format_ = '%03d'\n",
        "        start, end = int(ranges[0][1:]), int(ranges[1][1:])\n",
        "    else:\n",
        "        prefix = ''\n",
        "        format_ = '%03d'\n",
        "        if len(ranges) == 1:\n",
        "            start = int(ranges[0])\n",
        "            end = start + 1\n",
        "        else:\n",
        "            start, end = int(ranges[0]), int(ranges[1])\n",
        "    return prefix, format_, start, end"
      ],
      "metadata": {
        "id": "m29VPX2zG3ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_levels(path, code_map: dict) -> np.ndarray:\n",
        "    print('generating code levels ...')\n",
        "    three_level_code_set = set(code.split('.')[0] for code in code_map)\n",
        "    icd9_path = os.path.join(path, 'icd9.txt')\n",
        "    icd9_range = list(open(icd9_path, 'r', encoding='utf-8').readlines())\n",
        "    three_level_dict = dict()\n",
        "    level1, level2, level3 = (1, 1, 1)\n",
        "    level1_can_add = False\n",
        "    for range_ in icd9_range:\n",
        "        range_ = range_.rstrip()\n",
        "        if range_[0] == ' ':\n",
        "            prefix, format_, start, end = parse_icd9_range(range_)\n",
        "            level2_cannot_add = True\n",
        "            for i in range(start, end + 1):\n",
        "                code = prefix + format_ % i\n",
        "                if code in three_level_code_set:\n",
        "                    three_level_dict[code] = [level1, level2, level3]\n",
        "                    level3 += 1\n",
        "                    level1_can_add = True\n",
        "                    level2_cannot_add = False\n",
        "            if not level2_cannot_add:\n",
        "                level2 += 1\n",
        "        else:\n",
        "            if level1_can_add:\n",
        "                level1 += 1\n",
        "                level1_can_add = False\n",
        "\n",
        "    level4 = 1\n",
        "    code_level = dict()\n",
        "    for code in code_map:\n",
        "        three_level_code = code.split('.')[0]\n",
        "        if three_level_code in three_level_dict:\n",
        "            three_level = three_level_dict[three_level_code]\n",
        "            code_level[code] = three_level + [level4]\n",
        "            level4 += 1\n",
        "        else:\n",
        "            print(three_level_code)\n",
        "            code_level[code] = [0, 0, 0, 0]\n",
        "\n",
        "    code_level_matrix = np.zeros((len(code_map) + 1, 4), dtype=int)\n",
        "    for code, cid in code_map.items():\n",
        "        code_level_matrix[cid] = code_level[code]\n",
        "\n",
        "    return code_level_matrix"
      ],
      "metadata": {
        "id": "t4wpNpxFHHNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_patient_code_adjacent(code_x: np.ndarray, code_num: int) -> np.ndarray:\n",
        "    print('generating patient code adjacent matrix ...')\n",
        "    result = np.zeros((len(code_x), code_num + 1), dtype=int)\n",
        "    for i, codes in enumerate(code_x):\n",
        "        adj_codes = codes[codes > 0]\n",
        "        result[i][adj_codes] = 1\n",
        "    return result"
      ],
      "metadata": {
        "id": "l3lQFXptHJ_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_code_code_adjacent(code_num: int, code_level_matrix: np.ndarray) -> np.ndarray:\n",
        "    print('generating code code adjacent matrix ...')\n",
        "    n = code_num + 1\n",
        "    result = np.zeros((n, n), dtype=int)\n",
        "    for i in range(1, n):\n",
        "        print('\\r\\t%d / %d' % (i, n), end='')\n",
        "        for j in range(1, n):\n",
        "            if i != j:\n",
        "                level_i = code_level_matrix[i]\n",
        "                level_j = code_level_matrix[j]\n",
        "                same_level = 4\n",
        "                while same_level > 0:\n",
        "                    level = same_level - 1\n",
        "                    if level_i[level] == level_j[level]:\n",
        "                        break\n",
        "                    same_level -= 1\n",
        "                result[i, j] = same_level + 1\n",
        "    print('\\r\\t%d / %d' % (n, n))\n",
        "    return result"
      ],
      "metadata": {
        "id": "Om1W6dplHMFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def co_occur(pids: np.ndarray,\n",
        "             patient_admission: dict,\n",
        "             admission_codes_encoded: dict,\n",
        "             code_num: int) -> (np.ndarray, np.ndarray, np.ndarray):\n",
        "    print('calculating co-occurrence ...')\n",
        "    x = np.zeros((code_num + 1, code_num + 1), dtype=float)\n",
        "    for i, pid in enumerate(pids):\n",
        "        print('\\r\\t%d / %d' % (i + 1, len(pids)), end='')\n",
        "        admissions = patient_admission[pid]\n",
        "        for k, admission in enumerate(admissions[:-1]):\n",
        "            codes = admission_codes_encoded[admission['admission_id']]\n",
        "            for m in range(len(codes) - 1):\n",
        "                for n in range(m + 1, len(codes)):\n",
        "                    c_i, c_j = codes[m], codes[n]\n",
        "                    x[c_i, c_j] = 1\n",
        "                    x[c_j, c_i] = 1\n",
        "    print('\\r\\t%d / %d' % (len(pids), len(pids)))\n",
        "    return x"
      ],
      "metadata": {
        "id": "wJeJyHtcHOm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = raw_path\n",
        "code_levels = generate_code_levels(data_path, code_map)\n",
        "patient_code_adj = generate_patient_code_adjacent(code_x=train_codes_x, code_num=code_num)\n",
        "code_code_adj_t = generate_code_code_adjacent(code_level_matrix=code_levels, code_num=code_num)\n",
        "co_occur_matrix = co_occur(train_pids, patient_admission, admission_codes_encoded, code_num)\n",
        "code_code_adj = code_code_adj_t * co_occur_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egNIhPWuHQW8",
        "outputId": "86774c84-f152-4add-fda0-b73e0e33b651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating code levels ...\n",
            "generating patient code adjacent matrix ...\n",
            "generating code code adjacent matrix ...\n",
            "\t4881 / 4881\n",
            "calculating co-occurrence ...\n",
            "\t7000 / 7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l1 = len(train_pids)\n",
        "train_patient_ids = np.arange(0, l1)\n",
        "l2 = l1 + 0\n",
        "l3 = l2 + len(test_pids)\n",
        "test_patient_ids = np.arange(l2, l3)\n",
        "pid_map = dict()\n",
        "for i, pid in enumerate(train_pids):\n",
        "    pid_map[pid] = train_patient_ids[i]\n",
        "for i, pid in enumerate(test_pids):\n",
        "    pid_map[pid] = test_patient_ids[i]"
      ],
      "metadata": {
        "id": "TcAg3HjUHSmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code_levels = code_levels[1:][:]                      # code_levels --> Remove first row\n",
        "patient_code_adj = np.delete(patient_code_adj, 0, 1)  # patient_code_adj --> Remove first column\n",
        "code_code_adj = np.delete(code_code_adj[1:][:], 0, 1) # code_code_adj --> Remove first row & column"
      ],
      "metadata": {
        "id": "ZbFbRYxgHU0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patients = pd.read_csv(\"/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/PATIENTS.csv\")\n",
        "train_mort = np.zeros(len(train_pids))\n",
        "for i in range(len(train_pids)):\n",
        "  train_mort[i] = int(patients.loc[patients[\"SUBJECT_ID\"] == train_pids[i]][\"EXPIRE_FLAG\"])\n",
        "test_mort = np.zeros(len(test_pids))\n",
        "for i in range(len(test_pids)):\n",
        "  test_mort[i] = int(patients.loc[patients[\"SUBJECT_ID\"] == test_pids[i]][\"EXPIRE_FLAG\"])"
      ],
      "metadata": {
        "id": "5aXYLSZwLr0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_train_codes_x = []\n",
        "for i in range(len(train_pids)):\n",
        "  one_patient = np.zeros((train_visit_lens[i], code_num))\n",
        "  for ii in range(train_visit_lens[i]):\n",
        "    temp = train_codes_x[i][ii]\n",
        "    temp = temp[temp > 0] - 1\n",
        "    one_patient[ii][temp] = 1\n",
        "  binary_train_codes_x.append(one_patient)\n",
        "\n",
        "binary_test_codes_x = []\n",
        "for i in range(len(test_pids)):\n",
        "  one_patient = np.zeros((test_visit_lens[i], code_num))\n",
        "  for ii in range(test_visit_lens[i]):\n",
        "    temp = test_codes_x[i][ii]\n",
        "    temp = temp[temp > 0] - 1\n",
        "    one_patient[ii][temp] = 1\n",
        "  binary_test_codes_x.append(one_patient)"
      ],
      "metadata": {
        "id": "1Z7Swt9FPs88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_train_codes_x.pkl', 'wb') as f0:\n",
        "  pickle.dump(binary_train_codes_x, f0)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/binary_test_codes_x.pkl', 'wb') as f1:\n",
        "  pickle.dump(binary_test_codes_x, f1)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_codes_y.npy', 'wb') as f2:\n",
        "  np.save(f2, train_codes_y)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_visit_lens.npy', 'wb') as f3:\n",
        "  np.save(f3, train_visit_lens)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/train_mort.npy', 'wb') as f4:\n",
        "  np.save(f4, train_mort)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_codes_y.npy', 'wb') as f5:\n",
        "  np.save(f5, test_codes_y)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_visit_lens.npy', 'wb') as f6:\n",
        "  np.save(f6, test_visit_lens)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Binary_Data_Format/test_mort.npy', 'wb') as f7:\n",
        "  np.save(f7, test_mort)"
      ],
      "metadata": {
        "id": "POtGS8gdavBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/train_codes_x.npy', 'wb') as f8:\n",
        "  np.save(f8, train_codes_x)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/test_codes_x.npy', 'wb') as f9:\n",
        "  np.save(f9, test_codes_x)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/train_codes_y.npy', 'wb') as fa:\n",
        "  np.save(fa, train_codes_y)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/train_visit_lens.npy', 'wb') as fb:\n",
        "  np.save(fb, train_visit_lens)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/train_mort.npy', 'wb') as fc:\n",
        "  np.save(fc, train_mort)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/test_codes_y.npy', 'wb') as fd:\n",
        "  np.save(fd, test_codes_y)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/test_visit_lens.npy', 'wb') as fe:\n",
        "  np.save(fe, test_visit_lens)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/Nonbinary_Data_Format/test_mort.npy', 'wb') as ff:\n",
        "  np.save(ff, test_mort)"
      ],
      "metadata": {
        "id": "F7NQ8LTocdMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/code_related/code_levels.npy', 'wb') as f10:\n",
        "  np.save(f10, code_levels)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/code_related/patient_code_adj.npy', 'wb') as f11:\n",
        "  np.save(f11, patient_code_adj)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/code_related/code_code_adj.npy', 'wb') as f12:\n",
        "  np.save(f12, code_code_adj)\n",
        "\n",
        "with open('/content/drive/MyDrive/CEED/MIMIC_Data/III/June_Preprocessed/code_related/code_map.pkl', 'wb') as f13:\n",
        "  pickle.dump(code_map, f13)"
      ],
      "metadata": {
        "id": "PtaRq3kcdkoJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}